---
title: "Hands-on_Ex10"
author: "Lau Jia Yi"
date: November 5, 2024
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

# **15  Processing and Visualising Flow Data**

## **15.1 Overview**

Spatial interaction represent the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.

Each spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or a spatial interaction matrix.

In this hands-on exercise, you will learn how to build an OD matrix by using [*Passenger Volume by Origin Destination Bus Stops*](https://r4gdsa.netlify.app/chap15) data set downloaded from [LTA DataMall](https://datamall.lta.gov.sg/content/datamall/en.html). By the end of this hands-on exercise, you will be able:

-   to import and extract OD data for a selected time interval,

-   to import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,

-   to populate planning subzone code into bus stops sf tibble data frame,

-   to construct desire lines geospatial data from the OD data, and

-   to visualise passenger volume by origin and destination bus stops by using the desire lines data.

## **15.2 Getting Started**

For the purpose of this exercise, five r packages will be used. They are:

-   [sf](https://r-spatial.github.io/sf/) for importing, integrating, processing and transforming geospatial data.

-   [tidyverse](https://www.tidyverse.org/) for importing, integrating, wrangling and visualising data.

-   [tmap](https://r-tmap.github.io/tmap/) for creating elegent and cartographic quality thematic maps.

-   [stplanr](https://docs.ropensci.org/stplanr/) provides functions for solving common problems in transport planning and modelling such as downloading and cleaning transport datasets; creating geographic “desire lines” from origin-destination (OD) data; route assignment, locally and interfaces to routing services such as CycleStreets.net; calculation of route segment attributes such as bearing and aggregate flow; and ‘travel watershed’ analysis.

-   [DT](https://rstudio.github.io/DT/) provides an R interface to the JavaScript library DataTables. R data objects (matrices or data frames) can be displayed as tables on HTML pages, and DataTables provides filtering, pagination, sorting, and many other features in the tables.

```{r}
pacman::p_load(tmap, sf, DT, stplanr, tidyverse)
```

## **15.3 Preparing the Flow Data**

### **15.3.1 Importing the OD data**

Firstly, we will import the *Passenger Volume by Origin Destination Bus Stops* data set downloaded from LTA DataMall by using `read_csv()` of **readr** package.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202210.csv")
```

Let use display the *odbus* tibble data table by using the code chunk below.

```{r}
glimpse(odbus)
```

A quick check of odbus tibble data frame shows that the values in OROGIN_PT_CODE and DESTINATON_PT_CODE are in numeric data type. Hence, the code chunk below is used to convert these data values into character data type.

```{r eval=FALSE}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE) 
```

### **15.3.2 Extracting the study data**

For the purpose of this exercise, we will extract commuting flows on weekday and between 6 and 9 o’clock.

```{r eval=FALSE}
odbus6_9 <- odbus %>%
  filter(DAY_TYPE == "WEEKDAY") %>%
  filter(TIME_PER_HOUR >= 6 &
           TIME_PER_HOUR <= 9) %>%
  group_by(ORIGIN_PT_CODE,
           DESTINATION_PT_CODE) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS))
```

We will save the output in rds format for future used.

```{r eval=FALSE}
write_rds(odbus6_9, "data/rds/odbus6_9.rds")}
```

The code chunk below will be used to import the save odbus6_9.rds into R environment.

```{r}
odbus6_9 <- read_rds("data/rds/odbus6_9.rds")
```

Table below shows the content of odbus6_9

```{r}
datatable(odbus6_9)
```

## **15.4 Working with Geospatial Data**

For the purpose of this exercise, two geospatial data will be used. They are:

-   BusStop: This data provides the location of bus stop as at last quarter of 2022.

-   MPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019.

Both data sets are in ESRI shapefile format.

### **15.4.1 Importing geospatial data**

Two geospatial data will be used in this exercise, they are:

```{r}
busstop <- st_read(dsn = "data/geospatial",
                   layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                   layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

```{r}
mpsz
```

::: callout-note
-   `st_read()` function of sf package is used to import the shapefile into R as sf data frame.

-   `st_transform()` function of sf package is used to transform the projection to crs 3414.
:::

The code chunk below will be used to write mpsz sf tibble data frame into an rds file for future use.

```{r}
mpsz <- write_rds(mpsz, "data/rds/mpsz.rds")
```

## **15.5 Geospatial data wrangling**

### **15.5.1 Combining Busstop and mpsz**

Code chunk below populates the planning subzone code (i.e. SUBZONE_C) of mpsz sf data frame into busstop sf data frame.

```{r}
busstop_mpsz <- st_intersection(busstop, mpsz) %>%
  select(BUS_STOP_N, SUBZONE_C) %>%
  st_drop_geometry()
```

::: callout-note
-   `st_intersection()` is used to perform point and polygon overly and the output will be in point sf object.

-   `select()` of dplyr package is then use to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame.

-   five bus stops are excluded in the resultant data frame because they are outside of Singapore bpundary.
:::

```{r}
datatable(busstop_mpsz)
```

Before moving to the next step, it is wise to save the output into rds format.

```{r}
write_rds(busstop_mpsz, "data/rds/busstop_mpsz.rds")  
```

Next, we are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.

```{r}
od_data <- left_join(odbus6_9 , busstop_mpsz,
            by = c("ORIGIN_PT_CODE" = "BUS_STOP_N")) %>%
  rename(ORIGIN_BS = ORIGIN_PT_CODE,
         ORIGIN_SZ = SUBZONE_C,
         DESTIN_BS = DESTINATION_PT_CODE)
```

Before continue, it is a good practice for us to check for duplicating records.

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

If duplicated records are found, the code chunk below will be used to retain the unique records.

```{r}
od_data <- unique(od_data)
```

It will be a good practice to confirm if the duplicating records issue has been addressed fully.

Next, we will update od_data data frame cwith the planning subzone codes.

```{r}
od_data <- left_join(od_data , busstop_mpsz,
            by = c("DESTIN_BS" = "BUS_STOP_N")) 
```

```{r}
duplicate <- od_data %>%
  group_by_all() %>%
  filter(n()>1) %>%
  ungroup()
```

```{r}
od_data <- unique(od_data)
```

```{r}
od_data <- od_data %>%
  rename(DESTIN_SZ = SUBZONE_C) %>%
  drop_na() %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarise(MORNING_PEAK = sum(TRIPS))
```

It is time to save the output into an rds file format.

```{r}
write_rds(od_data, "data/rds/od_data_fii.rds")
```

```{r}
od_data_fii <- read_rds("data/rds/od_data.rds")
```

## **15.6 Visualising Spatial Interaction**

In this section, you will learn how to prepare a desire line by using **stplanr** package.

### **15.6.1 Removing intra-zonal flows**

We will not plot the intra-zonal flows. The code chunk below will be used to remove intra-zonal flows.

```{r}
od_data_fij <- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]
```

```{r}
write_rds(od_data_fij, "data/rds/od_data_fij.rds")
```

```{r}
od_data_fij <- read_rds("data/rds/od_data_fij.rds")
```

### **15.6.2 Creating desire lines**

In this code chunk below, `od2line()` of **stplanr** package is used to create the desire lines.

```{r}
flowLine <- od2line(flow = od_data_fij, 
                    zones = mpsz,
                    zone_code = "SUBZONE_C")
```

```{r}
write_rds(flowLine, "data/rds/flowLine.rds")
```

```{r}
flowLine <- read_rds("data/rds/flowLine.rds")
```

### **15.6.3 Visualising the desire lines**

To visualise the resulting desire lines, the code chunk below is used.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

::: (.warning}
Be patient, the rendering process takes more time because of the transparency argument (i.e. alpha)
:::

When the flow data are very messy and highly skewed like the one shown above, it is wiser to focus on selected flows, for example flow greater than or equal to 5000 as shown below.

```{r}
tm_shape(mpsz) +
  tm_polygons() +
flowLine %>%  
  filter(MORNING_PEAK >= 5000) %>%
tm_shape() +
  tm_lines(lwd = "MORNING_PEAK",
           style = "quantile",
           scale = c(0.1, 1, 3, 5, 7, 10),
           n = 6,
           alpha = 0.3)
```

# **16  Calibrating Spatial Interaction Models with R**

## **16.1 Overview**

Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).

There are four main types of traditional SIMs (Wilson 1971):

-   Unconstrained

-   Production-constrained

-   Attraction-constrained

-   Doubly-constrained

Ordinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.

::: callout-note
Calibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)
:::

## **16.2 The Case Study and Data**

In this exercise, we are going to calibrate SIM to determine factors affecting the public bus passenger flows during the morning peak in Singapore.

## **16.3 Getting Started**

For the purpose of this exercise, four r packages will be used. They are:

-   sf for importing, integrating, processing and transforming geospatial data.

-   tidyverse for importing, integrating, wrangling and visualising data.

-   tmap for creating thematic maps.

```{r}
pacman::p_load(tmap, sf, sp,
               performance, reshape2,
               ggpubr, tidyverse)
```

## **16.4 The Data**

This exercise is a continuation of **Chapter 15: Processing and Visualising Flow Data** and the following data will be used:

-   *od_data.rds*, weekday morning peak passenger flows at planning subzone level.

-   *mpsz.rds*, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

Beside these two data sets, an additional attribute data file called pop.csv will be provided. It

## **16.5 Computing Distance Matrix**

In spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location’s distance from itself, which is shown in the main diagonal of the table, is 0.

In this section, you will learn how to compute a distance matrix by using URA Master Plan 2019 Planning Subzone boundary in which you saved as an rds file called *mpsz*.

First, let us import *mpsz.rds* into R environemnt by using the code chunk below.

```{r}
mpsz <- read_rds("data/rds/mpsz.rds")
mpsz
```

Notice that it is a sf tibble dataframe object class.

### **16.5.1 Converting from sf data.table to SpatialPolygonsDataFrame**

There are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.

First [`as.Spatial()`](https://r-spatial.github.io/sf/reference/coerce-methods.html) will be used to convert *mpsz* from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.

```{r}
mpsz_sp <- as(mpsz, "Spatial")
mpsz_sp
```

### **16.5.2 Computing the distance matrix**

Next, [`spDists()`](https://www.rdocumentation.org/packages/sp/versions/2.1-1/topics/spDistsN1) of sp package will be used to compute the Euclidean distance between the centroids of the planning subzones.

::: {.callout-tip}
Do you know why the distance is calculated between two centroids of a pair of spatial polygons?

-   Consistency as centroids represent a central point within each polygon, providing a single consistent reference for distance calculations.
:::

```{r}
dist <- spDists(mpsz_sp,
                longlat = FALSE)
```

```{r}
head(dist, n=c(10, 10))
```

Notice that the output *dist* is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes.

### **16.5.3 Labelling column and row heanders of a distance matrix**

First, we will create a list sorted according to the the distance matrix by planning sub-zone code.

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next we will attach `SUBZONE_C` to row and column for distance matrix matching ahead

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

### **16.5.4 Pivoting distance value by SUBZONE_C**

Next, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

Notice that the within zone distance is 0.

### **16.5.5 Updating intra-zonal distances**

In this section, we are going to append a constant value to replace the intra-zonal distance of 0.

First, we will select and find out the minimum value of the distance by using `summary()`.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

The code chunk below will be used to check the result data.frame.

```{r}
distPair %>%
  summary()
```

The code chunk below is used to rename the origin and destination fields.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

Lastly, the code chunk below is used to save the dataframe for future use.

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

```{r}
distPair <- read_rds("data/rds/distPair.rds")
```

## **16.6 Preparing flow data**

The code chunk below is used import *od_data* save in Chapter 15 into R environment.

```{r}
od_data_fii <- read_rds("data/rds/od_data_fii.rds")
```

Next, we will compute the total passenger trip between and within planning subzones by using the code chunk below. The output is all *flow_data*.

```{r}
flow_data <- od_data_fii %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 
```

Use the code chunk below to display flow_data dataframe.

```{r}
head(flow_data, 10)
```

### **16.6.1 Separating intra-flow from passenger volume df**

Code chunk below is used to add three new fields in `flow_data` dataframe.

```{r}
flow_data$FlowNoIntra <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)
flow_data$offset <- ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

### **16.6.2 Combining passenger volume data with distance value**

Before we can join *flow_data* and *distPair*, we need to convert data value type of *ORIGIN_SZ* and *DESTIN_SZ* fields of flow_data dataframe into factor data type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

Now, `left_join()` of **dplyr** will be used to *flow_data* dataframe and *distPair* dataframe. The output is called *flow_data1*.

```{r}
flow_data1 <- flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## **16.7 Preparing Origin and Destination Attributes**

### **16.7.1 Importing population data**

```{r}
pop <- read_csv("data/aspatial/pop.csv")
```

### **16.7.2 Geospatial data wrangling**

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

### **16.7.3 Preparing origin attribute**

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### **16.7.4 Preparing destination attribute**

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

We will called the output data file *SIM_data*. it is in rds data file format.

```{r}
write_rds(flow_data1, "data/rds/SIM_data.rds")
```

## **16.8 Calibrating Spatial Interaction Models**

In this section, you will learn how to calibrate Spatial Interaction Models by using Poisson Regression method.

### **16.8.1 Importing the modelling data**

Firstly, let us import the modelling data by using the code chunk below.

```{r}
SIM_data <- read_rds("data/rds/SIM_data.rds")
```

### **16.8.2 Visualising the dependent variable**

Firstly, let us plot the distribution of the dependent variable (i.e. TRIPS) by using histogram method by using the code chunk below.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```

Notice that the distribution is highly skewed and not resemble bell shape or also known as normal distribution.

Next, let us visualise the relation between the dependent variable and one of the key independent variable in Spatial Interaction Model, namely distance.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

```

Notice that their relationship hardly resemble linear relationship.

On the other hand, if we plot the scatter plot by using the log transformed version of both variables, we can see that their relationship is more resemble linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

### **16.8.3 Checking for variables with zero values**

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that no 0 values in the explanatory variables.

In the code chunk below, summary() of Base R is used to compute the summary statistics of all variables in *SIM_data* data frame.

```{r}
summary(SIM_data)
```

The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

In view of this, code chunk below will be used to replace zero values to 0.99.

```{r}
SIM_data$DESTIN_AGE7_12 <- ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 <- ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 <- ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 <- ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 <- ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 <- ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)
```

You can run the summary() again.

```{r}
summary(SIM_data)
```

Notice that all the 0 values have been replaced by 0.99.

### **16.8.4 Unconstrained Spatial Interaction Model**

In this section, you will learn how to calibrate an unconstrained spatial interaction model by using `glm()` of Base Stats. The explanatory variables are origin population by different age cohort, destination population by different age cohort (i.e. *ORIGIN_AGE25_64*) and distance between origin and destination in km (i.e. *dist*).

The general formula of Unconstrained Spatial Interaction Model

![](images/clipboard-2098303418.png)

The code chunk used to calibrate to model is shown below:

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM
```

### **16.8.5 R-squared function**

In order to measure how much variation of the trips can be accounted by the model we will write a function to calculate R-Squared value as shown below.

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed,estimated)
  R2 <- r^2
  R2
}
```

Next, we will compute the R-squared of the unconstrained SIM by using the code chunk below.

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

```{r}
r2_mcfadden(uncSIM)
```

### **16.8.6 Origin (Production) constrained SIM**

In this section, we will fit an origin constrained SIM by using the code3 chunk below.

The general formula of Origin Constrained Spatial Interaction Model

![](images/clipboard-2418230122.png)

```{r}
orcSIM <- glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(orcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### **16.8.7 Destination constrained**

In this section, we will fit a destination constrained SIM by using the code chunk below.

The general formula of Destination Constrained Spatial Interaction Model

```{r}
decSIM <- glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(decSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### **16.8.8 Doubly constrained**

In this section, we will fit a doubly constrained SIM by using the code chunk below.

The general formula of Doubly Constrained Spatial Interaction Model

![](images/clipboard-1522313502.png)

```{r}
dbcSIM <- glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(dbcSIM)
```

We can examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

Notice that there is a relatively greater improvement in the R\^2 value.

### **16.8.9 Model comparison**

Another useful model performance measure for continuous dependent variable is [Root Mean Squared Error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e). In this sub-section, you will learn how to use [`compare_performance()`](https://easystats.github.io/performance/reference/compare_performance.html) of [**performance**](https://easystats.github.io/performance/index.html) package

First of all, let us create a list called *model_list* by using the code chun below.

```{r}
model_list <- list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

Next, we will compute the RMSE of all the models in *model_list* file by using the code chunk below.

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

The print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.

### **16.8.10 Visualising fitted values**

In this section, you will learn how to visualise the observed values and the fitted values.

Firstly we will extract the fitted values from each model by using the code chunk below.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

Next, we will join the values to *SIM_data* data frame.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

Repeat the same step by for Origin Constrained SIM (i.e. orcSIM)

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")
```

Repeat the same step by for Destination Constrained SIM (i.e. decSIM)

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%   
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%   cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")
```

Repeat the same step by for Doubly Constrained SIM (i.e. dbcSIM)

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)
```

```{r}
SIM_data <- SIM_data %>%   cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")
```

```{r}
unc_p <- ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

Now, we will put all the graphs into a single visual for better comparison by using the code chunk below.

```{r}
ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
